>[!note]
>이 절에서는 빅데이터의 주요 역사에 대해서 설명한다.
>- 2011까지는 Hadoop이나 NoSQL 데이터베이스 등 기반 기술의 발전
>- 2012까지는 클라우드 방식의 데이터 웨어하우스나 BI 도구의 보급
>- 2013까지는 스트림 처리나 애드 혹(AdHoc) 분석 환경의 확충
# 분산 시스템에 의한 데이터 처리의 고속화
> 빅데이터의 취급하기 어려운 점을 극복한 두 가지 대표 기술

- 빅데이터라는 단어를 대중 매체를 통해 접하게 된 것은 2011년 후반, 많은 기업들이 데이터 처리에 분산 시스템을 도입하기 시작했을 무렵
	- 이 때부터 데이터를 비즈니스에 활용하자는 움직임이 활발해짐
- 현재로서는 `빅데이터의 기술이 큰 어려움 없이 안심하고 사용할 수 있다`라고 말하기는 어려운 상황이며, `데이터를 모아서 무엇을 할 것인가?`에 대해서도 아직은 명확하게 해답을 내리기 어려운 상황
	- 첫번째 이유 : 데이터의 분석법을 모른다.
	- 두번째 이유 : 데이터 처리에 수고와 시간이 걸린다.
- 이 책에서는 전자의 문제는 논의하지 않음. 알고 싶은 정보가 있다는 전제하에 `어떻게 효율적으로 실행할 것인가?`를 고민하는 것이 이 책의 목표

## 빅데이터 기술의 요구
> Hadoop과 NoSQL의 대두

![그림 1.1 Hadoop과 NoSQL의 위치 관계](https://blog.kakaocdn.net/dn/dhswXK/btrgvVJgftT/RCL2V2cBkjb65DkqM60ew1/img.jpg)

- 인터넷의 보급으로 세계 곳곳으로부터 액세스 되는 시스템이 증가함에 따라 RDB로는 취급할 수 없을 만큼 대량의 데이터가 쌓이게 됨
	- 이를 위한 데이터 처리 구조가 필요해 Hadoop과 NoSQL이 각각 다른 요구를 위해 태어남.

## Hadoop
> 다수의 컴퓨터에서 대량의 데이터 처리

- 예를 들어, 전 세계의 웹페이지를 모아서 검색 엔진을 제작
	- 방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리할 수 있는 구조가 필요
	- 그러기 위해, 수백 또는 수천 대 단위의 컴퓨터가 필요
- 이 많은 컴퓨터를 관리하는 것이 `Hadoop`이라는 프레임 워크
- `Hadoop`은 원래 구글에서 개발된 분산 처리 프레임워크인 `MapReduce`를 참고하여 제작됨.
	- 초기에는 `MapReduce`를 동작시키려면 데이터 처리의 내용을 기술하기 위해 자바 언어로 프로그래밍 해야 했음.
	- 그렇기에 ==누구나 간단히 사용하지 못했음==
- 그래서 SQL과 같은 쿼리 언어를 `Hadoop`에서 실행하기 위한 소프트웨어로 `Hive`가 개발되어 2009년에 출시
	- 이로 인해 자바 프로그래밍 없이 데이터를 집계할 수 있게 됨.

## NoSQL 데이터베이스
> 빈번한 읽기/쓰기 및 분산 처리가 강점

- 전통적인 RDB의 제약을 제거하여 읽기/쓰기의 속도를 높인 방식이 `NoSQL`
	- NoSQL에는 다양한 종류가 존재, 아래 기술들이 대표적
		- 다수의 키와 값을 관련지어 저장하는 `키 벨류 스토어`
		- `JSON` 같은 복잡한 데이터 구조를 저장하는 `도큐먼트 스토어`
		- 여러 키를 상ㅇ하여 높은 확장성을 제공하는 `와이드 칼럼 스토어`

>[!important]
>모여진 데이터를 나중에 집계하는 것이 목적인 Hadoop과는 다르게 NoSQL은 애플리케이션에서 온라인으로 접속하는 데이터베이스이다.

### Hadoop과 NoSQL DB의 조합
> 현실적인 비용으로 대규모 데이터 처리 실현

- NoSQL DB에 기록하고, Hadoop으로 분산처리하는 흐름이 지배적
- 방대한 데이터 규모에 비해, 기존의 기술로는 불가능하거나 고가의 HW가 필요한 경우에도, `현실적인 비용으로 데이터를 처리할 수 있게 된 것`

# 분산 시스템의 비즈니스 이용 개척
> 데이터 웨어하우스와의 공존

- 일부 기업에서는 이전부터 데이터 분석을 기반으로 하는 **`엔터프라이즈 데이터 웨어하우스`** 또는 **`데이터 웨어하우스`** 를 도입했다.
	- 해당 데이터를 오랜 기간에 걸쳐 축적되고, 그것을 분석함으로써 업무 개선과 경영 판단의 자료로 활용되었다.
- 분산 시스템의 발전에 따라, 기존이라면 데이터 웨어하우스 제품이 사용되는 경우에도 Hadoop을 사용하는 경우가 증가함
	- 다수의 데이터 분석 도구가 Hadoop을 이용하기 시작함. 따라서 Hadoop과 Hive를 사용하게 됨.
		- 물론 데이터 웨어하우스에서도 대량의 데이터 처리가 가능하고, 여러 방면에서 우수함
		- 하지만 데이터 용량을 늘리려면 HW를 교체하는 등 Scale-out이 쉽지 않았음.
	- 그 결과 Hadoop의 도입을 기술적으로 지원하는 비즈니스가 성립하게 됨.
	- 따라서 **가속도적으로 늘어나는 데이터 처리는 Hadoop에 맡기고, 비교적 작은 데이터, 또는 중요한 데이터 만을 데이터 웨어하우스에 넣는 식**으로 사용을 구분하게 됨.

>[!note]
>예를 들어, 심야에 대량으로 발생하는 데이터 처리에 Hadoop을 사용하고, 야간 배치에서는 매일 거래되는 데이터 등을 심야에 집계해 다음 날 아침까지 보고서에 정리한다.
>데이터 양이 증가하면 배치 처리 또한 시간이 걸려 dependent한 task에도 업무에 지장이 생긴다.
>
>이런 상황에서 확장성이 뛰어난 Hadoop에 데이터 처리를 맡김으로써 데이터 웨어하우스의 부담을 줄인다. 

![그림 1.2 하둡에 의한데이터 웨어하우스의 증가](https://velog.velcdn.com/images/whattsup_kim/post/bba5d249-4b40-44ca-b9ae-610c8deb83be/image.png)

# 직접 할 수 있는 데이터 분석 폭 확대
> 클라우드 서비스와 데이터 디스커버리로 가속하는 빅데이터의 활용

- 이와 비슷한 시기부터 클라우드 서비스의 보급에 의해 빅데이터의 활용이 증가하였다. 
	- 여러컴퓨터에서 분산 처리한다는 점이 빅데이터의 데이터 처리 방식이므로 클러스터링과 연관되어 기술이 발전함.
- 클라우드 시대인 요즘은 시간 단위로 필요한 자원을 확보할 수 있어서 방법만 알면 언제든지 이용할 수 있는 환경이 마련됨.
- 2012년 말에, 데이터 웨어 하우스를 클라우드 상에서 작성하는 것은 드문 일이 아니었다.
	- 작은 프로젝트 단위에서도 자체적인 데이터 분석 기반을 마련하는 게 일반적이게 될 정도

>[!important]
>기존 기술을 이용해서 취급할 수 있는 작은 데이터를 `스몰 데이터`라고 할 때, 빅데이터와의 본질적인 차이는 없다.
>대량의 데이터인 경우, 과거라면 버릴 수 밖에 없었던 데이터였지만, 빅데이터의 시대가 되니 그것마저도 모두 처리할 수 있게 됨.
>
>즉 데이터 분석 방법은 스몰 데이터 시절부터 이미 존재하였기에 결국은 `효율`의 문제임.
>따라서 효율적인 스몰 데이터 처리 방법을 알지 못한 채, 빅데이터 기술만 배워서는 충분하지 않고, 이 둘을 적재적소로 구사하는 것이 이상적이다.

## 데이터 디스커버리의 기초지식
> 셀프서비스용 BI 도구

- 빅데이터 기술이 나오면서, 저장된 데이터를 시각화하려는 방법으로 `데이터 디스커버리`가 인기를 끌게 됨.
	- `데이터 디스커버리`란 **대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스**를 말함.
- 데이터 디스커버리는 `셀프 서비스용 BI(Business Intelligence) 도구`로 불림
	- 예전부터 데이터 웨어하우스와 조합되어 사용된 경영자용 시각화 시스템
	- tool 자체는 개인도 도입할 수 있을 정도로 단순화한 것으로, 이로 인해 점차 많은 사람이 데이터를 살펴볼 수 있게 되었다.
- 2013년 이후에도, 빅데이터 기술은 더 높은 `효율`과 `편리성`을 실현하기 위해 발전
	- `Apache Spark`같은 새로운 분산 시스템용 프레임 워크가 개발되어, 효율적인 데이터 처리가 가능해짐.
	- 배치 처리 뿐만 아니라 실시간 데이터 처리를 위한 시스템도 다수 만들어지고 있음.